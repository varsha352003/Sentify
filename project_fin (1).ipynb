{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9941b8-cf04-4dcb-98bb-a5476418e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have a lot of datasets  we will take a small sample of dataset to work on i.e.aroung 50k \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf22b90-17c9-467e-931b-6bc947b3fc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id   ProductId          UserId             ProfileName  \\\n",
      "0  165257  B000EVG8J2  A1L01D2BD3RKVO  B. Miller \"pet person\"   \n",
      "1  231466  B0000BXJIS  A3U62RE5XZDP0G                   Marty   \n",
      "2  427828  B008FHUFAU   AOXC0JQQZGGB6         Kenneth Shevlin   \n",
      "3  433955  B006BXV14E  A3PWPNZVMNX3PA             rareoopdvds   \n",
      "4   70261  B007I7Z3Z0  A1XNZ7PCE45KK7                  Og8ys1   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     0                       0      5  1268179200   \n",
      "1                     0                       0      5  1298937600   \n",
      "2                     0                       2      3  1224028800   \n",
      "3                     0                       1      2  1335312000   \n",
      "4                     0                       2      5  1334707200   \n",
      "\n",
      "                                        Summary  \\\n",
      "0  Crunchy & Good Gluten-Free Sandwich Cookies!   \n",
      "1                            great kitty treats   \n",
      "2                                  COFFEE TASTE   \n",
      "3              So the Mini-Wheats were too big?   \n",
      "4                             Great Taste . . .   \n",
      "\n",
      "                                                Text  \n",
      "0  Having tried a couple of other brands of glute...  \n",
      "1  My cat loves these treats. If ever I can't fin...  \n",
      "2  A little less than I expected.  It tends to ha...  \n",
      "3  First there was Frosted Mini-Wheats, in origin...  \n",
      "4  and I want to congratulate the graphic artist ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\Asus\\Contacts\\Desktop\\data sci work\\nlp\\sa+rs\\Reviews.csv')\n",
    "\n",
    "# Take a random sample of 100,000 rows\n",
    "# fin_df = df.sample(n=50000, random_state=42)  # random_state ensures reproducibility\n",
    "\n",
    "# # Save the sampled data to a new file\n",
    "# fin_df.to_csv(r'C:\\Users\\Asus\\Contacts\\Desktop\\data sci work\\nlp\\sa+rs\\fin_reviews.csv', index=False)\n",
    "\n",
    "# Now, you can load the sampled data from the new file to work on it consistently\n",
    "fin_data = pd.read_csv(r'C:\\Users\\Asus\\Contacts\\Desktop\\data sci work\\nlp\\sa+rs\\fin_reviews.csv')\n",
    "\n",
    "# Check the first few rows\n",
    "print(fin_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc5f61a-e633-46a7-a710-7c76b4ecfcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will use this fin data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd811128-b592-4350-87df-07a1585b8b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      50000 non-null  int64 \n",
      " 1   ProductId               50000 non-null  object\n",
      " 2   UserId                  50000 non-null  object\n",
      " 3   ProfileName             50000 non-null  object\n",
      " 4   HelpfulnessNumerator    50000 non-null  int64 \n",
      " 5   HelpfulnessDenominator  50000 non-null  int64 \n",
      " 6   Score                   50000 non-null  int64 \n",
      " 7   Time                    50000 non-null  int64 \n",
      " 8   Summary                 49999 non-null  object\n",
      " 9   Text                    50000 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "fin_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222b1657-578f-4df5-87c6-bd18d566500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score\n",
       "5    32097\n",
       "4     7008\n",
       "1     4528\n",
       "3     3791\n",
       "2     2576\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c857a629-b141-459a-ad6a-6bbdcf03a9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77bb733e-fea7-4481-9ada-a173f3f3af48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        0\n",
       "ProductId                 0\n",
       "UserId                    0\n",
       "ProfileName               0\n",
       "HelpfulnessNumerator      0\n",
       "HelpfulnessDenominator    0\n",
       "Score                     0\n",
       "Time                      0\n",
       "Summary                   1\n",
       "Text                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d484262-3761-4411-bf33-faa1eb83de2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         int64\n",
       "ProductId                 object\n",
       "UserId                    object\n",
       "ProfileName               object\n",
       "HelpfulnessNumerator       int64\n",
       "HelpfulnessDenominator     int64\n",
       "Score                      int64\n",
       "Time                       int64\n",
       "Summary                   object\n",
       "Text                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bedaa70-18f1-4717-a6ae-1ae236c9b8cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fin_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_new\u001b[38;5;241m=\u001b[39m fin_data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfileName\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHelpfulnessNumerator\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHelpfulnessDenominator\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_new\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fin_data' is not defined"
     ]
    }
   ],
   "source": [
    "df_new= fin_data.drop(['ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time','Id'],axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "017a70ad-4aac-45ff-8750-84bfc8ea64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.to_csv(r'C:\\Users\\Asus\\Contacts\\Desktop\\data sci work\\nlp\\sa+rs\\cleaned_reviews_final.csv', index=False) #after dropping some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcbd6462-2277-47ce-938c-be981cac1a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change data type of summary and text\n",
    "df_new['Summary']=df_new['Summary'].astype(str)\n",
    "type(df_new['Summary'].iloc[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2ae28b-400c-4cb9-8b7d-248434048d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to tokenize\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "def tokenize_text(text):\n",
    "    doc = nlp(text)  \n",
    "    return [token.text for token in doc]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c2e4af4-798d-4ca9-8311-534ebfe3bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Summary  \\\n",
      "0  Crunchy & Good Gluten-Free Sandwich Cookies!   \n",
      "1                            great kitty treats   \n",
      "2                                  COFFEE TASTE   \n",
      "3              So the Mini-Wheats were too big?   \n",
      "4                             Great Taste . . .   \n",
      "\n",
      "                                       Summ_tokenize  \n",
      "0  [Crunchy, &, Good, Gluten, -, Free, Sandwich, ...  \n",
      "1                             [great, kitty, treats]  \n",
      "2                                    [COFFEE, TASTE]  \n",
      "3      [So, the, Mini, -, Wheats, were, too, big, ?]  \n",
      "4                            [Great, Taste, ., ., .]  \n"
     ]
    }
   ],
   "source": [
    "df_new['Summ_tokenize']=df_new['Summary'].apply(tokenize_text)\n",
    "print(df_new[['Summary','Summ_tokenize']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b06d92-f76b-4ba7-ad41-dbced4081b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Text_tokenize']=df_new['Text'].apply(tokenize_text)\n",
    "print(df_new[['Text','Text_tokenize']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "338f3b5c-83f1-4e24-bf65-867fa731d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert tokenized text dataset int csv\n",
    "#df_new.to_csv(r'C:\\Users\\Asus\\Contacts\\Desktop\\data sci work\\nlp\\sa+rs\\tokenized_reviews.csv', index=False) #after dropping some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d831bf8a-83e4-4b9e-8008-8fd465cedcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e11a967-a310-43a7-9cf1-15bd4dfcf7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78cf7e9-1568-4fa5-9d57-b4724c8640d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bcce482-72df-418f-8684-00eda1ba10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS -= {\"not\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753a745e-eb48-457b-95a8-93e6cd588a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7547b77-4f82-420e-8992-0f3b312bdc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "is\n",
      "not\n"
     ]
    }
   ],
   "source": [
    "t=nlp(\"he is not looking good\")\n",
    "for token in t:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d236c41-e3c1-4b20-bc3f-fcdac24d6e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Remove \"not\" from the stop word list\n",
    "stop_words.discard(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8f7b9f6-ec37-4670-931e-35479aea5b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "t=nlp(\"he is not looking good\")\n",
    "for token in t:\n",
    "    if token.text in stop_words:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "651cba27-b51b-42cb-bd11-ec7cef7f6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    filtered_tokens=[token for token in tokens if token.lower() not in stop_words and  token.isalpha()]\n",
    "    return(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53bee8a8-fc68-4264-a4ab-46795666db80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductId        object\n",
       "UserId           object\n",
       "Score             int64\n",
       "Summary          object\n",
       "Text             object\n",
       "Summ_tokenize    object\n",
       "Text_tokenize    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "470bd48b-ba5c-4f5e-a384-345b56ad974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"processed_text\"]=df_new['Text_tokenize'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d6839c8-c203-4811-a12b-9e8e7ecb72d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Having, tried, couple, brands, gluten, free, ...\n",
       "1    [cat, loves, treats, find, house, pop, bolts, ...\n",
       "2    [little, expected, tends, muddy, taste, not, e...\n",
       "3    [Frosted, Mini, Wheats, original, size, Froste...\n",
       "4    [want, congratulate, graphic, artist, putting,...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"processed_text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1239a23-b0fe-4c7d-bdeb-4c7687ec4a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Crunchy, Good, Gluten, Free, Sandwich, Cookies]\n",
       "1                              [great, kitty, treats]\n",
       "2                                     [COFFEE, TASTE]\n",
       "3                                 [Mini, Wheats, big]\n",
       "4                                      [Great, Taste]\n",
       "Name: processed_summary, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"processed_summary\"]=df_new['Summ_tokenize'].apply(remove_stop_words)\n",
    "df_new[\"processed_summary\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b12893-a6a6-478e-81a8-4d9315a0e27b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_new\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAsus\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mContacts\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata sci work\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msa+rs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprocessed_reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "df_new.to_csv(r'C:\\Users\\Asus\\Contacts\\Desktop\\data sci work\\nlp\\sa+rs\\processed_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a02771-c57f-447d-8b05-6e6c7aa215ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next step is Lemmatization\n",
    "def lemmatize_text(tokens):\n",
    "      \n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    lemmatized_tokens = [token.lemma_ for token in tokens]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50c38b-ce08-43c4-8027-9cf868e875c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
